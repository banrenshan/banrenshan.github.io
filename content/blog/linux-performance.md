---
title: linux性能管理
tags:
  - linux
categories:
  - 操作系统
  - linux
date: 2022-12-01 11:21:20
---



# 性能指标

## CPU

CPU 是操作系统稳定运行的根本，CPU 的速度与性能很大一部分决定了系统整体的性能，因此 CPU 数量越多、主频越高，服务器性能也就相对越好。  

但亊实也并非完全如此，目前大部分 CPU 在同一时间内只能运行一个线程，超线程的处理器可以在同一时间运行多个线程，因而可以利用处理器的超线程特性提髙系统性能。  

而在 Linux 系统下，只有运行 SMP 内核才能支持超线程，但是安装的 CPU 数量越多，从超线程获得的性能上的提高就越少。另外，Linux 内核会把多核的处理器当作多个单独的 CPU 来识别，例如两颗 4 核的 CPU 在 Linux 系统下会认为是 8 颗 CPU。  

注意，从性能角度来讲，两颗 4 核的 CPU 和 8 颗单核的 CPU 并不完全等价，根据权威部门得出的测试结论，前者的整体性能要低于后者 25%〜30%。

在 Linux 系统中，邮件服务器、动态 Web 服务器等应用对 CPU 性能的要求相对较高，因此对于这类应用，要把 CPU 的配置和性能放在主要位置。

## 内存

内存的大小也是影响 Linux 性能的一个重要的因素。内存太小，系统进程将被阻塞，应用也将变得缓慢，甚至失去响应；内存太大，会导致资源浪费。  

Linux 系统采用了物理内存和虚拟内存的概念，虚拟内存虽然可以缓解物理内存的不足，但是占用过多的虚拟内存，应用程序的性能将明显下降。要保证应用程序的高性能运行，物理内存一定要足够大，但不应过大，否则会造成内存资源的浪费。  

例如，在一个 32 位处理器的 Linux 操作系统上，超过 8GB 的物理内存都将被浪费。因此，要使用更大的内存，建议安装 64 位的操作系统，同时开启 Linux 的大内存内核支持。  

不仅如此，由于处理器寻址范围的限制，在 32 位 Linux 操作系统上，应用程序单个进程最大只能使用 2GB 的内存。这样即使系统有更大的内存，应用程序也无法“享”用，解决的办法就是使用 64 位处理器，安装 64 位操作系统，在 64 位操作系统下，可以满足所有应用程序对内存的使用需求，几乎没有限制。  

对内存性能要求比较的应用有打印服务器、数据库服务器和静态 Web 服务器等，因此对于这类应用，要把内存大小放在主要位置。



## 磁盘读写（I/O）能力

磁盘的 I/O 能力会直接影响应用程序的性能。比如说，在一个需要频繁读写的应用中，如果磁盘 I/O 性能得不到满足，就会导致应用的停滞。  

不过，好在现今的磁盘都采用了很多方法来提高 I/O 性能，比如常见的磁盘 RAID 技术。  

RAID 的英文全称为 Redundant Array of Independent Disks，翻译成中文为独立磁盘冗余阵列，简称磁盘阵列。RAID 通过把多块独立的磁盘（物理硬盘）按不同方式组合起来，形成一个磁盘组（逻辑硬盘），从而提供比单个硬盘更高的 I/O 性能和数据冗余。  

通过 RAID 技术组成的磁盘组，就相当于一个大硬盘，用户可以对它进行分区格式化、建立文件系统等操作，跟单个物理硬盘一模一样，惟一不同的是 RAID 磁盘组的 I/O 性能比单个硬盘要高很多，同时对数据的安全性也有很大提升。  

有关 RAID 更多的介绍，可阅读《[Linux RAID（磁盘列阵）完全攻略](http://c.biancheng.net/view/vip_5093.html)》一节做深入了解。

## 网络带宽

Linux 下的各种应用，一般都是基于网络的，因此网络带宽也是影响性能的一个重要因素，低速的、不稳定的网络将导致网络应用程序的访问阻塞；而稳定、高速的带宽，可以保证应用程序在网络上畅通无阻地运行。  

幸运的是，现在的网络一般都是千兆带宽，或者光纤网络，带宽问题对应用程序性能造成的影响也在逐步降低。  

通过对以上 4 个方面的讲述，不难看出，各个方面之间都是相互依赖的，不能孤立地从某个方面来排查问题。换句话说，当一个方面出现性能问题时，往往会引发其他方面出现问题。  

例如，大量的磁盘读写势必消耗 CPU 和 I/O 资源，而内存的不足会导致频繁地进行内存页写入磁盘、磁盘写到内存的操作，造成磁盘 I/O 瓶颈，同时大量的网络流量也会造成 CPU 过载。总之，在处理性能问题时，应纵观全局，从各个方面进行综合考虑。





# 性能监控命令



## netstat：查看网络端口

/etc/services 文件下记录了服务和端口的映射关系。

netstat命令用来查看端口信息，主要选项：

- -a：列出系统中所有网络连接，包括已经连接的网络服务、监听的网络服务和 Socket 套接字；

- -t：列出 TCP 数据；

- -u：列出 UDF 数据；

- -l：列出正在监听的网络服务（不包含已经连接的网络服务）；

- -n：用端口号来显示而不用服务名；

- -p：列出该服务的进程 ID (PID)；



```shell
[root@localhost ~]# netstat -tlunp
#列出系统中所有已经启动的服务（已经监听的端口），但不包含已经连接的网络服务
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name
tcp 0 0 0.0.0.0:53575 0.0.0.0:*
LISTEN
1200/rpc.statd
tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1181/rpcbind
tcp 0 0 0.0.0.0:22 O.O.O.O:* LISTEN 1405/sshd
tcp 0 0 127.0.0.1:631 O.O.O.O:* LISTEN 1287/cupsd
tcp 0 0 127.0.0.1:25 O.O.O.O:* LISTEN 1481/master
```

执行这条命令会看到服务器上所有已经开启的端口，也就是说，通过这些端口就可以知道当前服务器上开启了哪些服务。

解释一下命令的执行结果：

- Proto：数据包的协议。分为 TCP 和 UDP 数据包；

- Recv-Q：表示收到的数据已经在本地接收缓冲，但是还没有被进程取走的数据包数量；

- Send-Q：对方没有收到的数据包数量；或者没有 Ack 回复的，还在本地缓冲区的数据包数量；

- Local Address：本地 IP : 端口。通过端口可以知道本机开启了哪些服务；

- Foreign Address：远程主机：端口。也就是远程是哪个 IP、使用哪个端口连接到本机。由于这条命令只能查看监听端口，所以没有 IP 连接到到本机；

- State:连接状态。主要有已经建立连接（ESTABLISED）和监听（LISTEN）两种状态，当前只能查看监听状态；

- PID/Program name：进程 ID 和进程命令；



```
[root@localhost ~]# netstat -an
#查看所有的网络连接，包括已连接的网络服务、监听的网络服务和Socket套接字
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address Foreign Address State
tcp 0 0 0.0.0.0:53575 0.0.0.0:* LISTEN
tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN
tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN
tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN
tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN
tcp 0 0 192.168.0.210:22 192.168.0.105:4868 ESTABLISHED
tcp 0 0 :::57454 :::* LISTEN
...省略部分输出...
udp 0 0 :::932 :::*
Active UNIX domain sockets (servers and established)
Proto RefCnt Flags Type State I-Node Path
#Socket套接字输出,后面有具体介绍
Unix 2 [ ACC ] STREAM LISTENING 11712 /var/run/dbus/system_bus_socket
unix 2 [ ACC ] STREAM LISTENING 8450 @/com/ubuntu/upstart unix 7. [ ] DGRAM 8651 @/org/kernel/udev/udevd
unix 2 [ ACC ] STREAM LISTENING 11942 @/var/run/hald/dbus-b4QVLkivf1
...省略部分输出...
```

执行"netstat -an"命令能査看更多的信息，在 Stated 中也看到了已经建立的连接（ESTABLISED）。这是 ssh 远程管理命令产生的连接，ssh 对应的端口是 22。  

而且我们还看到了 Socket 套接字。在服务器上，除网络服务可以绑定端口，用端口来接收客户端的请求数据外，系统中的网络程序或我们自己开发的网络程序也可以绑定端口，用端口来接收客户端的请求数据。这些网络程序就是通过 Socket 套接字来绑定端口的。也就是说，网络服务或网络程序要想在网络中传递数据，必须利用 Socke 套接字绑定端口，并进行数据传递。  

使用"netstat -an"命令查看到的这些 Socke 套接字虽然不是网络服务，但是同样会占用端口，并在网络中传递数据。  

解释一下 Socket 套接字的输出：

- Proto：协议，一般是unix；

- RefCnt：连接到此Socket的进程数量；

- Flags：连接标识；

- Type：Socket访问类型；

- State：状态，LISTENING表示监听，CONNECTED表示已经建立连接；

- I-Node：程序文件的 i 节点号；

- Path：Socke程序的路径，或者相关数据的输出路径；



## vmstat命令

vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。

```shell
[root@localhost ~]# vmstat 2 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
1  0      8 247512  39660 394168    0    0    31     8   86  269  0  1 98  1  0
0  0      8 247480  39660 394172    0    0     0     0   96  147  4  0 96  0  0
0  0      8 247484  39660 394172    0    0     0    66   95  141  2  2 96  0  0
```

- Procs（进程） 

  - r: 运行队列中进程数量,也就是多少个进程分配到了CPU，当这个值超过了CPU的数目，表示CPU出现瓶颈了。

  - b: 表示阻塞的进程，比如正在等待I/O或者内存交换等

- Memory（内存） 

  - swpd: 使用虚拟内存大小 ，如果大于0，表示你的机器物理内存不足了。

  - free: 空闲物理内存大小 

  - buff: 用作缓冲的内存大小 ，一般对块设备的读写才需要缓冲。

  - cache: 表示page cached的内存大小，也就是缓存大小。频繁访问的文件会被缓存到内存当中。如果cache值比较大，而IO中的bi比较小，说明文件系统效率比较好。

- Swap 

  - si: 表示有磁盘调入内存，也就是内存进入内存交换区的内存大小；通俗的讲就是 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。 

  - so: 每秒写入交换区的内存大小，由内存调入磁盘 。

  - 一般情况下si、so的值都为0，如果si、so的值长期不为0，则说明系统内存不足，需要增加系统内存

- IO（现在的Linux版本块的大小为1kb）

  - bi: 每秒读取的块数 

  - bo: 每秒写入的块数 

  - 如果bi+bo的值过大，且wa值较大，则表示系统磁盘IO瓶颈

- system（系统） 

  - in: 每秒中断数，包括时钟中断 

  - cs: 每秒上下文切换数 

  - 这两个值越大，则由内核消耗的CPU就越多

- CPU（以百分比表示） 

  - us: 用户进程执行时间百分比(user time),us的值比较高时，说明用户进程消耗的CPU时间多。 如果长期大于50%，则需要考虑优化程序或者算法

  - sy: 内核系统进程执行时间百分比(system time),sy的值高时，说明系统内核消耗的CPU资源多。 一般来说us+sy应该小于80%，如果大于80%，说明可能存在CPU瓶颈

  - wa: IO等待时间百分比,wa的值高时，说明IO等待比较严重。引起I/O等待的原因可能是磁盘大量随机读写造成的，也可能是磁盘或者服务器的带宽瓶颈造成的。 

  - id: 表示CPU处在空间状态的时间百分比

## sar命令

sar 命令很强大，是分析系统性能的重要工具之一，通过该命令可以全面地获取系统的 CPU、运行队列、磁盘读写（I/O）、分区（交换区）、内存、CPU 中断和网络等性能数据。  

sar 命令的基本格式如下：

```
[root@localhost ~]# sar [options] [-o filename] interval [count]
```

此命令格式中，各个参数的含义如下：

- -o filename：其中，filename 为文件名，此选项表示将命令结果以二进制格式存放在文件中；

- interval：表示采样间隔时间，该参数必须手动设置；

- count：表示采样次数，是可选参数，其默认值为 1；

- options：为命令行选项，由于 sar 命令提供的选项很多，这里不再一一介绍，仅列举出常用的一些选项及对应的功能，如表 1 所示。

| sar命令选项 | 功能                                                         |
| ----------- | ------------------------------------------------------------ |
| -A          | 显示系统所有资源设备（CPU、内存、磁盘）的运行状况。          |
| -u          | 显示系统所有 CPU 在采样时间内的负载状态。                    |
| -P          | 显示当前系统中指定 CPU 的使用情况。                          |
| -d          | 显示系统所有硬盘设备在采样时间内的使用状态。                 |
| -r          | 显示系统内存在采样时间内的使用情况。                         |
| -b          | 显示缓冲区在采样时间内的使用情况。                           |
| -v          | 显示 inode 节点、文件和其他内核表的统计信息。                |
| -n          | 显示网络运行状态，此选项后可跟 DEV（显示网络接口信息）、EDEV（显示网络错误的统计数据）、SOCK（显示套接字信息）和 FULL（等同于使用 DEV、EDEV和SOCK）等，有关更多的选项，可通过执行 man sar 命令查看。 |
| -q          | 显示运行列表中的进程数、进程大小、系统平均负载等。           |
| -R          | 显示进程在采样时的活动情况。                                 |
| -y          | 显示终端设备在采样时间的活动情况。                           |
| -w          | 显示系统交换活动在采样时间内的状态。                         |

【例 1】如果想要查看系统 CPU 的整理负载状况，每 3 秒统计一次，统计 5 次，可以执行如下命令：

```shell
[root@localhost ~]# sar -u 3 5
Linux 2.6.32-431.el6.x86_64 (localhost)  10/28/2019  _x86_64_ (8 CPU)

04:02:46 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle
04:02:49 AM     all      1.69      0.00      2.03      0.00      0.00     96.27
04:02:52 AM     all      1.68      0.00      0.67      0.34      0.00     97.31
04:02:55 AM     all      2.36      0.00      1.69      0.00      0.00     95.95
04:02:58 AM     all      0.00      0.00      1.68      0.00      0.00     98.32
04:03:01 AM     all      0.33      0.00      0.67      0.00      0.00     99.00
Average:        all      1.21      0.00      1.35      0.07      0.00     97.37
```

此输出结果统计的是系统中包含的 8 颗 CPU 的整体运行状况，每项的输出都非常直观，其中最后一行（Average）是汇总行，是对上面统计信息的一个平均值。

需要指出的是，sar 输出结果中第一行包含了 sar 命令本身的统计消耗，因此 %user 列的值会偏高一点，但这并不会对统计结果产生很大影响。

另外，在一个多 CPU 的系统中，如果程序使用了单线程，就会出现“CPU 整体利用率不高，但系统应用响应慢”的现象，造成此现象的原因在于，单线程只使用一个 CPU，该 CPU 占用率为 100%，无法处理其他请求，但除此之外的其他 CPU 却处于闲置状态，进而整体 CPU 使用率并不高。  

针对这个问题，可以使用 sar 命令单独查看系统中每个 CPU 的运行状态，例如：

```shell
[root@localhost ~]# sar -P 0 3 5
Linux 2.6.32-431.el6.x86_64 (localhost)  10/28/2019  _x86_64_ (8 CPU)

04:44:57 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle
04:45:00 AM       0      8.93      0.00      1.37      0.00      0.00     89.69
04:45:03 AM       0      6.83      0.00      1.02      0.00      0.00     92.15
04:45:06 AM       0      0.67      0.00      0.33      0.33      0.00     98.66
04:45:09 AM       0      0.67      0.00      0.33      0.00      0.00     99.00
04:45:12 AM       0      2.38      0.00      0.34      0.00      0.00     97.28
Average:          0      3.86      0.00      0.68      0.07      0.00     95.39
```

注意，sar 命令对系统中 CPU 的计数是从数字 0 开始的，因此上面执行的命令表示对系统中第一颗 CPU 的运行状态进行统计。如果想单独统计系统中第 5 颗 CPU 的运行状态，可以执行sar -P 4 3 5命令。

【例 2】如果想要查看系统磁盘的读写性能，可执行如下命令：

```shell
[root@localhost ~]# sar -d 3 5
Linux 2.6.32-431.el6.x86_64 (localhost)     10/25/2019     _x86_64_    (1 CPU)

06:36:52 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
06:36:55 AM    dev8-0      3.38      0.00    502.26    148.44      0.08     24.11      4.56      1.54

06:36:55 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
06:36:58 AM    dev8-0      1.49      0.00     29.85     20.00      0.00      1.75      0.75      0.11

06:36:58 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
06:37:01 AM    dev8-0     68.26      6.96  53982.61    790.93      3.22     47.23      3.54     24.17

06:37:01 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
06:37:04 AM    dev8-0    111.69   3961.29    154.84     36.85      1.05      9.42      3.44     38.43

06:37:04 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
06:37:07 AM    dev8-0      1.67    136.00      2.67     83.20      0.01      6.20      6.00      1.00

Average:          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
Average:       dev8-0     34.45    781.10   9601.22    301.36      0.78     22.74      3.50     12.07
```

此输出结果中，各个列表头的含义如下：

- tps：每秒从物理磁盘 I/O 的次数。注意，多个逻辑请求会被合并为一个 I/O 磁盘请求，一次传输的大小是不确定的；

- rd_sec/s：每秒读扇区的次数；

- wr_sec/s：每秒写扇区的次数；

- avgrq-sz：平均每次设备 I/O 操作的数据大小（扇区）；

- avgqu-sz：磁盘请求队列的平均长度；

- await：从请求磁盘操作到系统完成处理，每次请求的平均消耗时间，包括请求队列等待时间，单位是毫秒（1 秒=1000 毫秒）；

- svctm：系统处理每次请求的平均时间，不包括在请求队列中消耗的时间；

- %util：I/O 请求占 CPU 的百分比，比率越大，说明越饱和。



【例 2】如果想要查看内存的使用情况，可执行如下命令：

```shell
[root@localhost ~]# sar -r 2 3
Linux 2.6.32-431.el6.x86_64 (localhost)  10/29/2019  _x86_64_ (8 CPU)

04:54:20 AM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit
04:54:22 AM   1218760    834228     40.63     53228    424908    738312     18.08
04:54:24 AM   1218744    834244     40.64     53228    424908    738312     18.08
04:54:26 AM   1218712    834276     40.64     53228    424908    738312     18.08
Average:      1218739    834249     40.64     53228    424908    738312     18.08
```

此输出结果中，各个参数表示的含义如下：

- kbmemfree：表示空闲的物理内存的大小；

- kbmemeused：表示已使用的物理内存的大小；

- %memused：表示已使用内存占总内存大小的百分比；

- kbbuffers：表示缓冲区所使用的物理内存的大小；

- kbcached：表示告诉缓存所使用的物理内存的大小；

- kbcommit 和 %commit：分别表示当前系统中应用程序使用的内存大小和百分比；

相比 free 命令，sar 命令的输出信息更加人性化，不仅给出了内存使用量，还给出了内存使用的百分比以及统计的平均值。比如说，仅通过 %commit 一项就可以得知，当前系统中的内存资源充足。







## iostat

iostat 命令主要用于统计磁盘 I/O 状态，但也能用来查看 CPU 的使用情况，只不过使用此命令仅能显示系统所有 CPU 的平均状态，无法向 sar 命令那样做具体分析。  

使用 iostat 命令查看 CPU 运行状态，需要使用该命令提供的 -c 选项，该选项的作用是仅显示系统 CPU 的运行情况。例如：

```shell
[root@localhost ~]# iostat -c
Linux 2.6.32-431.el6.x86_64 (localhost)  10/28/2019  _x86_64_ (8 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.07    0.00    0.12    0.09    0.00   99.71
```

可以看到，此输出结果中包含的项和 sar 命令的输出项完全相同。

## uptime 

uptime 命令是监控系统性能最常用的一个命令，主要用来统计系统当前的运行状况。例如：

```shell
[root@localhost ~]# uptime
05:38:26 up  1:47,  2 users,  load average: 0.12, 0.08, 0.08
```

该命令的输出结果中，各个数据所代表的含义依次是：系统当前时间、系统运行时长、当前登陆系统的用户数量、系统分别在 1 分钟、5 分钟和 15 分钟内的平均负载。  

这里需要注意的是，load average 这 3 个输出值一般不能大于系统 CPU 的个数。例如，本测试系统有 8 个 CPU，如果 load average 中这 3 个值长期大于 8，就说明 CPU 很繁忙，负载很高，系统性能可能会受到影响；如果偶尔大于 8 则不用担心，系统性能一般不会受到影响；如果这 3 个值小于 CPU 的个数（如本例所示），则表示 CPU 是非常空闲的。  

总的来说，本节介绍了 4 个可查看 CPU 性能的命令，但这些命令也仅能查看 CPU 是否繁忙、负载是否过大，无法知道造成这种现象的根本原因。因此，在明确判断出系统 CPU 出现问题之后，还要结合 top、ps 等命令，进一步检查出是哪些进程造成的。  

另外要知道的是，引发 CPU 资源紧张的原因有多个，可能是应用程序不合理造成的，也可能是硬件资源匮乏引起的。因此，要学会具体问题具体分析，或者优化应用程序，或者增加系统 CPU 资源。

## free

```shell
[root@localhost  ~]# free -m
             total       used       free     shared    buffers     cached
Mem:          2004        573       1431          0         47        201
-/+ buffers/cache:        323       1680
Swap:         1983          0       1983
```

从输出结果可以看到，该系统共 2GB 内存，其中系统空闲内存还有 1431MB，并且 swap 交换分区还未使用，因此可以判断出当前系统的内存资源还非常充足。  

除此之外，free 命令还可以实时地监控内存的使用状况，通过使用 -s 选项，可以实现在指定的时间段内不间断地监控内存的使用情况。例如：

```shell
[root@localhost ~]# free -m -s 5
             total       used       free     shared    buffers     cached
Mem:          2004        571       1433          0         47        202
-/+ buffers/cache:        321       1683
Swap:         1983          0       1983

             total       used       free     shared    buffers     cached
Mem:          2004        571       1433          0         47        202
-/+ buffers/cache:        321       1683
Swap:         1983          0       1983
#省略后续输出
```

要想实现动态地监控内存使用状况，除了使用 free 命令提供的 -s 选项，还可以借助 watch 命令。通过给 watch 命令后面添加需要运行的命令，watch 就会自行重复去运行这个命令（默认 2 秒执行一次），例如：

```shell
[root@localhost ~]# watch -n 3 -d free
Every 3.0s: free                                        Tue Oct 29 03:05:43 2019

             total       used       free     shared    buffers     cached
Mem:       2052988     586504    1466484          0      49184     207360
-/+ buffers/cache:     329960    1723028
Swap:      2031608          0    2031608
```

上面执行的命令中，-n 选项用于执行重复执行的间隔时间，-d 选项用于在显示数据时，高亮显示变动了的数据。



## dmesg：查看被内核杀死的进程

Linux dmesg（英文全称：display message）dmesg 命令主要用来显示内核信息。使用 dmesg 可以有效诊断机器硬件故障或者添加硬件出现的问题。另外，使用 dmesg 可以确定您的服务器安装了哪些硬件。每次系统重启，系统都会检查所有硬件并将信息记录下来。执行/bin/dmesg 命令可以查看该记录，开机信息亦保存在/var/log目录中，名称为dmesg的文件里。

也可以使用该命令查看进程被杀死的信息，如下：

```shell
$ dmesg | tail
[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
[...]
[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
```

该命令会输出系统日志的最后10行。示例中的输出，可以看见一次内核的oom kill和一次TCP丢包。这些日志可以帮助排查性能问题。千万不要忘了这一步。

## pidstat：查看进程的CPU

```shell
$ pidstat 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)
07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0
07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave
07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java
07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java
07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java
07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat
07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave
07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java
07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass
07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat
```

pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。
